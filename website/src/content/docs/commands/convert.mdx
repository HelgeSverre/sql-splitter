---
title: convert
description: Convert SQL dumps between MySQL, PostgreSQL, SQLite, and MSSQL
---

Transform SQL dumps between different database dialects.

**Alias:** `cv` (e.g., `sql-splitter cv mysql.sql --to postgres -o pg.sql`)

## When to Use This

- **Database migration** - Moving from MySQL to PostgreSQL (or any other combination)
- **Cross-platform development** - Convert production dumps to SQLite for local testing
- **Cloud migration** - Transform on-premise SQL Server dumps for cloud PostgreSQL
- **Tool compatibility** - Convert between dialects when tools only support specific formats

Use [`validate`](/commands/validate) after conversion to verify the output is valid for your target database.

## How It Works

The converter parses the source dump, transforms DDL (CREATE TABLE, indexes, constraints) and DML (INSERT, COPY) statements to the target dialect. This includes:

- **Identifier quoting** - Backticks (MySQL) ↔ double quotes (PostgreSQL/SQLite) ↔ brackets (MSSQL)
- **Data types** - Maps 50+ types between dialects (e.g., `AUTO_INCREMENT` → `SERIAL`)
- **Bulk import syntax** - Converts PostgreSQL `COPY ... FROM stdin` to INSERT statements for other dialects
- **String escaping** - Adapts escape sequences between dialects

## Usage

```bash
sql-splitter convert <INPUT> --to <DIALECT> [OPTIONS]
```

## Examples

### Basic Conversion

```bash
# MySQL to PostgreSQL
sql-splitter convert mysql.sql --to postgres -o pg.sql

# PostgreSQL to MySQL (COPY blocks become INSERT statements)
sql-splitter convert pg_dump.sql --to mysql -o mysql.sql

# Any dialect to SQLite (great for local development)
sql-splitter convert dump.sql --to sqlite -o sqlite.sql
```

### Explicit Source Dialect

Auto-detection works in most cases, but you can specify the source explicitly:

```bash
# When auto-detection fails or you want to be explicit
sql-splitter convert dump.sql --from mssql --to mysql -o mysql.sql
```

### Strict Mode for CI/CD

Use `--strict` to fail on any unsupported features instead of emitting warnings:

```bash
sql-splitter convert dump.sql --to postgres --strict
```

### Streaming Directly to Database

Pipe the converted output directly into your database client:

```bash
# Convert and restore in one step
sql-splitter convert mysql.sql.gz --to postgres -o - | psql "$PG_CONN"

# Convert and load into SQLite
sql-splitter convert pg_dump.sql --to sqlite -o - | sqlite3 dev.db
```

## Options

| Flag          | Short | Description                                            | Default     |
| ------------- | ----- | ------------------------------------------------------ | ----------- |
| `--output`    | `-o`  | Output SQL file or directory                           | stdout      |
| `--from`      |       | Source dialect: `mysql`, `postgres`, `sqlite`, `mssql` | auto-detect |
| `--to`        |       | Target dialect (required)                              | -           |
| `--strict`    |       | Fail on any unsupported feature                        | false       |
| `--progress`  | `-p`  | Show progress bar                                      | false       |
| `--dry-run`   |       | Preview without writing files                          | false       |
| `--fail-fast` |       | Stop on first error (for glob patterns)                | false       |
| `--json`      |       | Output results as JSON                                 | false       |

## Supported Conversions

All 12 conversion pairs are supported:

- MySQL ↔ PostgreSQL (including COPY → INSERT)
- MySQL ↔ SQLite
- MySQL ↔ MSSQL
- PostgreSQL ↔ SQLite
- PostgreSQL ↔ MSSQL
- SQLite ↔ MSSQL

## Type Mappings

50+ data type mappings are handled automatically:

| MySQL                | PostgreSQL   | SQLite                | MSSQL            |
| -------------------- | ------------ | --------------------- | ---------------- |
| `INT AUTO_INCREMENT` | `SERIAL`     | `INTEGER PRIMARY KEY` | `INT IDENTITY`   |
| `TINYINT(1)`         | `BOOLEAN`    | `INTEGER`             | `BIT`            |
| `VARCHAR(n)`         | `VARCHAR(n)` | `TEXT`                | `NVARCHAR(n)`    |
| `DATETIME`           | `TIMESTAMP`  | `TEXT`                | `DATETIME2`      |
| `TEXT`               | `TEXT`       | `TEXT`                | `NVARCHAR(MAX)`  |
| `BLOB`               | `BYTEA`      | `BLOB`                | `VARBINARY(MAX)` |

## PostgreSQL COPY Conversion

PostgreSQL's `COPY ... FROM stdin` format is converted to INSERT statements:

```sql
-- Input (PostgreSQL)
COPY users (id, name) FROM stdin;
1	Alice
2	Bob
\.

-- Output (MySQL)
INSERT INTO users (id, name) VALUES (1, 'Alice');
INSERT INTO users (id, name) VALUES (2, 'Bob');
```

## Warnings and Unsupported Features

The conversion **continues successfully** even when encountering unsupported features - they generate warnings but don't stop the process.

### Features that are converted with warnings

These types are converted to the closest equivalent, with a warning:

| Feature | Converted To | Notes |
|---------|--------------|-------|
| MySQL `ENUM('a','b','c')` | `VARCHAR(255)` (PostgreSQL/MSSQL) or `TEXT` (SQLite) | Enum values are lost; consider adding CHECK constraints manually |
| PostgreSQL arrays (`INT[]`) | `JSON` (MySQL), `TEXT` (SQLite), `NVARCHAR(MAX)` (MSSQL) | Data format preserved as JSON string |

### Features that are skipped entirely

These statements are **omitted from the output** (with a warning):

- `CREATE TRIGGER` - Trigger syntax is too dialect-specific to convert
- `CREATE PROCEDURE` / `CREATE FUNCTION` - Stored procedure logic cannot be automatically translated
- `CREATE TYPE` - Custom types have no equivalent in most dialects
- `CREATE DOMAIN` - PostgreSQL-specific
- `CREATE EXTENSION` - PostgreSQL-specific
- `CREATE SEQUENCE` - Skipped because `SERIAL`/`BIGSERIAL` columns are converted to `AUTO_INCREMENT`/`IDENTITY`, which handle sequencing automatically
- `COMMENT ON` - Not supported in all dialects

The command outputs a count of skipped statements at the end. Use `--strict` to fail instead of skipping.

See [Type Mappings Reference](/reference/type-mappings) for the complete list of 50+ type conversions.

## Troubleshooting

### Conversion fails on specific statements

If conversion fails completely (not just warnings), check:

1. **Syntax errors in source dump** - Validate first: `sql-splitter validate dump.sql`
2. **Wrong source dialect detected** - Specify explicitly: `--from mysql`
3. **Malformed statements** - The error message includes the problematic statement

### Output differs between runs

The converter preserves statement order from the input. If your dump has non-deterministic ordering (e.g., `mysqldump` without `--order-by-primary`, or tables listed in different order each time):

```bash
# Sort the dump first for stable, reproducible output
sql-splitter order dump.sql -o ordered.sql
sql-splitter convert ordered.sql --to postgres -o pg.sql
```

This is especially important for CI where you want to detect actual changes, not ordering noise.

### Wrong dialect auto-detected

Force the source dialect explicitly:
```bash
sql-splitter convert ambiguous.sql --from mysql --to postgres -o pg.sql
```

### Converted dump fails to import

1. **Validate the output**: `sql-splitter validate pg.sql --dialect postgres`
2. **Check for unsupported features**: Re-run with `--strict` to see all warnings
3. **Check type mappings**: See [Type Mappings Reference](/reference/type-mappings) for dialect-specific details

## See Also

- [`validate`](/commands/validate) - Validate converted output
- [Dialect Reference](/reference/dialects) - Detailed dialect information
- [Type Mappings Reference](/reference/type-mappings) - Data type conversion details
- [JSON Output Schema](/reference/json-output/) - Schema for `--json` output
